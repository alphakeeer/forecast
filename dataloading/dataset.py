import json, os, numpy as np, pandas as pd, xarray as xr, torch
from functools import lru_cache
import time

from torch.utils.data import Dataset
from dataloading.datayield  import yield_aligned_from_json
from dataloading.datayield import load_npy_files



class SimpleWindRadarDataset(Dataset):
    """
    åŸºç¡€ç‰ˆ Datasetï¼š
    - åˆå§‹åŒ–æ—¶ä¿å­˜ç”Ÿæˆå™¨å¯¹è±¡ï¼›
    - æ¯æ¬¡ __getitem__ ä»ç”Ÿæˆå™¨ä¸­å–æ ·å¹¶æ»‘çª—ç”Ÿæˆæ ·æœ¬ï¼›
    - ä¸éšæœºã€ä¸å¤šè¿›ç¨‹ï¼›
    - å†…å­˜å®‰å…¨ï¼ˆä¸ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®ï¼‰ã€‚
    """
    def __init__(self, json_path, radar_type="V05", input_len=12, pred_len=20, max_samples=None):
        self.gen = yield_aligned_from_json(json_path, radar_type=radar_type)
        self.input_len = input_len
        self.pred_len = pred_len
        self.buffer = []  # æš‚å­˜æ»‘çª—æ ·æœ¬
        self.exhausted = False
        self.max_samples = max_samples

    def _refill_buffer(self):
        """ä»ç”Ÿæˆå™¨ä¸­å–ä¸€ä¸ª key å¹¶ç”Ÿæˆæ‰€æœ‰æ»‘çª—"""
        try:
            key, wind, radar = next(self.gen)
        except StopIteration:
            self.exhausted = True
            return
        T = radar.shape[0]
        if T < self.input_len + self.pred_len:
            return
        for t in range(0, T - self.input_len - self.pred_len + 1):
            x = radar[t:t+self.input_len].astype(np.float32)
            y = wind[t+self.input_len:t+self.input_len+self.pred_len].astype(np.float32)
            self.buffer.append((x, y))

    def __getitem__(self, idx):
        # å½“ buffer ä¸ºç©ºæ—¶ï¼Œä»ç”Ÿæˆå™¨è¡¥å……æ•°æ®
        while not self.buffer and not self.exhausted:
            self._refill_buffer()
        if not self.buffer:
            raise IndexError("Dataset exhausted")
        return self.buffer.pop(0)

    def __len__(self):
        return self.max_samples or 10000  # è™šå€¼ï¼Œç”¨äº DataLoader é™åˆ¶è¿­ä»£æ¬¡æ•°

class FullSequenceWindRadarDataset(Dataset):
    """
    ğŸš€ çº¯åŠ è½½ Dataset
    - æ”¯æŒå¤šä¸ª radar_type
    - è®­ç»ƒæ—¶é…åˆ collate_fn æˆ–æ¨¡å‹å†…éƒ¨è¿›è¡Œçª—å£åŒ–
    - æ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œ + ç¼“å­˜
    """
    def __init__(self, json_path, radar_type=["V05","CR"], cache_size=32):
        with open(json_path, "r") as f:
            idx = json.load(f)
        self.wind_dict = idx["wind"]

        # æ£€æŸ¥é›·è¾¾ç±»å‹æ˜¯å¦éƒ½å­˜åœ¨
        self.radar_types = radar_type
        for rt in self.radar_types:
            if rt not in idx:
                raise ValueError(f"Radar type '{rt}' not found in dataset JSON keys: {list(idx.keys())}")

        # æ¯ç§é›·è¾¾ç±»å‹çš„ç´¢å¼•
        self.radar_dicts = {rt: idx[rt] for rt in self.radar_types}

        # ä»…ä¿ç•™åŒæ—¶å­˜åœ¨äº wind å’Œæ‰€æœ‰ radar ç±»å‹çš„ key
        self.keys = [
            k for k in self.wind_dict.keys()
            if all(k in self.radar_dicts[rt] for rt in self.radar_types)
        ]

        # ç¼“å­˜æœºåˆ¶
        self._load_key_data = lru_cache(maxsize=cache_size)(self._load_key_data_uncached)

    def __len__(self):
        return len(self.keys)

    def _load_key_data_uncached(self, key):
        wind_files = self.wind_dict[key]
        wind_data, wind_times = load_npy_files(wind_files)

        radar_datas = []
        radar_times_all = []

        # åŠ è½½æ¯ç§é›·è¾¾æ•°æ®
        for rt in self.radar_types:
            radar_files = self.radar_dicts[rt][key]
            radar_data, radar_times = load_npy_files(radar_files)
            radar_datas.append((radar_data, radar_times))
            radar_times_all.append(radar_times)

        # æ—¶é—´å¯¹é½èŒƒå›´
        start = min(wind_times.min(), *(rt.min() for _, rt in radar_datas)).floor("6min")
        end   = max(wind_times.max(), *(rt.max() for _, rt in radar_datas)).ceil("6min")
        grid  = pd.date_range(start, end, freq="6min")

        # å¯¹é½é£åœº
        da_wind = xr.DataArray(wind_data, coords={"time": wind_times}, dims=["time", "y", "x"])
        wind_aligned = da_wind.reindex(time=grid).values.astype(np.float32)

        # å¯¹é½å¤šä¸ªé›·è¾¾
        aligned_radars = []
        for radar_data, radar_times in radar_datas:
            da_radar = xr.DataArray(radar_data, coords={"time": radar_times}, dims=["time", "y", "x"])
            aligned = da_radar.reindex(time=grid).values.astype(np.float32)
            aligned_radars.append(aligned)

        # å †å å¤šä¸ªé›·è¾¾ç±»å‹ => shape: [num_types, time, y, x]
        radar_stacked = np.stack(aligned_radars, axis=0)

        return torch.from_numpy(radar_stacked), torch.from_numpy(wind_aligned)

    def __getitem__(self, idx):
        key = self.keys[idx]
        radar, wind = self._load_key_data(key)
        return key, radar, wind
    
def test_dataset_shapes_and_times():
    json_path = "/home/dataset-assist-0/data/data_index_flat_train.json"
    radar_types = ['CR', 'R05', 'RG1', 'RG2', 'V05', 'V15', 'VIL']# ä½ è¦æµ‹è¯•çš„é›·è¾¾ç±»å‹

    dataset = FullSequenceWindRadarDataset(json_path, radar_type=radar_types, cache_size=4)

    print(f"âœ… Total samples: {len(dataset)}")
    if len(dataset) == 0:
        print("âŒ Dataset is empty, please check your json or keys.")
        return

    # éšæœºæŠ½å‡ ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
    for i in range(min(3, len(dataset))):
        start_time = time.time()
        key, radar, wind = dataset[i]
        print(f"\nğŸŒ€ Sample {i} â€” key: {key}")

        # æ‰“å°åŸºæœ¬å½¢çŠ¶ä¿¡æ¯
        print(f"Radar shape: {radar.shape}")  # [num_types, time, y, x]
        print(f"Wind  shape: {wind.shape}")   # [time, y, x]

        e_time = time.time() - start_time
        print(f"â±ï¸  Load time: {e_time:.3f} seconds")

if __name__ == "__main__":
    test_dataset_shapes_and_times()