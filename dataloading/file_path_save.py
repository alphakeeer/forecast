import os
import glob
import json
import logging
from tqdm import tqdm
import random
from utils.logger_config import setup_logger
from tqdm.contrib.logging import logging_redirect_tqdm


def build_flat_data_index(
    base_dir="/home/dataset-assist-1/SevereWeather_AI_2025",
    save_path="data_index_flat.json",
    radar_types=("CR", "R05", "RG1", "RG2", "V05", "V15", "VIL")
):
    """
    æ„å»ºä¸€ä¸ªæ‰å¹³åŒ–çš„ JSON ç´¢å¼•:
    {
      "wind": { "TSW_00_03010941_00095": [path1, path2, ...], ... },
      "CR": { "TSW_00_03010941_00095": [path1, path2, ...], ... },
      ...
    }
    """
    logger = setup_logger()
    logger.info("å¼€å§‹æ„å»ºæ‰å¹³æ•°æ®ç´¢å¼•...")
    logger.info(f"åŸºç¡€ç›®å½•: {base_dir}")
    logger.info(f"ä¿å­˜è·¯å¾„: {save_path}")
    logger.info(f"é›·è¾¾ç±»å‹: {radar_types}")

    train_root = os.path.join(base_dir, "TSW", "TrainSet")
    if not os.path.exists(train_root):
        logger.error(f"âŒ è®­ç»ƒé›†ç›®å½•ä¸å­˜åœ¨: {train_root}")
        return None

    index_dict = {"wind": {}}
    for r in radar_types:
        index_dict[r] = {}

    idx_list = sorted(os.listdir(train_root))
    logger.info(f"å‘ç° {len(idx_list)} ä¸ªä¸€çº§ç›®å½• (ä¾‹å¦‚ 00, 01, 02...)")

    # å¤–å±‚è¿›åº¦æ¡ï¼šä¸€çº§ç›®å½•
    for idx in tqdm(idx_list, desc="ğŸ“‚ Scanning main folders", position=0):
        idx_dir = os.path.join(train_root, idx)
        if not os.path.isdir(idx_dir):
            logger.debug(f"è·³è¿‡éç›®å½•: {idx_dir}")
            continue

        subdirs = sorted(os.listdir(idx_dir))
        logger.info(f"[{idx}] å« {len(subdirs)} ä¸ªæ ·æœ¬ç›®å½•")

        # å†…å±‚è¿›åº¦æ¡ï¼šæ¯ä¸ªæ ·æœ¬ç›®å½•
        for sd in tqdm(subdirs, desc=f"   â†³ Processing {idx}", position=1, leave=False):
            sub_path = os.path.join(idx_dir, sd)
            if not os.path.isdir(sub_path):
                logger.debug(f"è·³è¿‡éç›®å½•: {sub_path}")
                continue

            key = sd[-15:]  # e.g. TSW_00_03010941_00095
            logger.debug(f"å¤„ç†æ ·æœ¬: {key}")

            # é£åœº (LABEL/WA)
            wind_pattern = os.path.join(sub_path, "LABEL", "WA", "*.npy")
            wind_files = sorted(glob.glob(wind_pattern))
            if wind_files:
                index_dict["wind"][key] = wind_files
                logger.debug(f"  ğŸŒ¬ï¸ é£åœºæ–‡ä»¶æ•°: {len(wind_files)}")

            # å„ç±»é›·è¾¾æ•°æ®
            radar_root = os.path.join(sub_path, "RADAR")
            if os.path.exists(radar_root):
                for rt in radar_types:
                    pattern = os.path.join(radar_root, rt, "*.npy")
                    radar_files = sorted(glob.glob(pattern))
                    if radar_files:
                        index_dict[rt][key] = radar_files
                        logger.debug(f"  ğŸ“¡ {rt} æ–‡ä»¶æ•°: {len(radar_files)}")
            else:
                logger.warning(f"æœªæ‰¾åˆ° RADAR ç›®å½•: {radar_root}")

    # ä¿å­˜ JSON æ–‡ä»¶
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(index_dict, f, indent=2, ensure_ascii=False)

    wind_count = len(index_dict["wind"])
    total_samples = sum(len(v) for v in index_dict.values())

    logger.info(f"âœ… æ‰å¹³ç´¢å¼•å·²ä¿å­˜åˆ°: {save_path}")
    logger.info(f"åŒ…å« {wind_count} ä¸ªé£åœºæ ·æœ¬ï¼Œæ€»è®¡ {total_samples} ä¸ªæ ·æœ¬ã€‚")
    print(f"\nâœ… ç´¢å¼•å·²å®Œæˆå¹¶ä¿å­˜åˆ°: {save_path}")
    print(f"é£åœºæ ·æœ¬: {wind_count} | æ€»æ ·æœ¬: {total_samples}")

    return index_dict

def split_data_index(
    json_path,
    out_dir=".",
    train_ratio=0.8,
    eval_ratio=0.1,
    test_ratio=0.1,
    seed=42
):
    """
    å°† build_flat_data_index ç”Ÿæˆçš„æ‰å¹³ JSON æŒ‰æ¯”ä¾‹æ‹†åˆ†ä¸º train/eval/test ä¸‰ä»½
    """
    logger = setup_logger()
    logger.info("ğŸ“‚ å¼€å§‹æ‹†åˆ†æ•°æ®ç´¢å¼•...")
    logger.info(f"è¾“å…¥æ–‡ä»¶: {json_path}")

    with open(json_path, "r", encoding="utf-8") as f:
        full_index = json.load(f)

    # ä½¿ç”¨ "wind" ä¸­çš„ key ä½œä¸ºä¸»æ ·æœ¬åˆ—è¡¨
    all_keys = sorted(full_index.get("wind", {}).keys())
    total = len(all_keys)
    if total == 0:
        logger.error("âŒ æ²¡æœ‰åœ¨ç´¢å¼•ä¸­æ‰¾åˆ° 'wind' æ ·æœ¬é”®ã€‚")
        return

    random.seed(seed)
    random.shuffle(all_keys)

    n_train = int(total * train_ratio)
    n_eval = int(total * eval_ratio)
    train_keys = set(all_keys[:n_train])
    eval_keys = set(all_keys[n_train:n_train + n_eval])
    test_keys = set(all_keys[n_train + n_eval:])

    logger.info(f"æ€»æ ·æœ¬: {total}")
    logger.info(f"è®­ç»ƒé›†: {len(train_keys)} | éªŒè¯é›†: {len(eval_keys)} | æµ‹è¯•é›†: {len(test_keys)}")

    def filter_subset(keys):
        """æ ¹æ®æŒ‡å®šæ ·æœ¬é”®è¿‡æ»¤æ•°æ®"""
        subset = {}
        for radar_type, samples in full_index.items():
            subset[radar_type] = {k: v for k, v in samples.items() if k in keys}
        return subset

    subsets = {
        "train": filter_subset(train_keys),
        "eval": filter_subset(eval_keys),
        "test": filter_subset(test_keys),
    }

    os.makedirs(out_dir, exist_ok=True)

    for name, data in subsets.items():
        save_path = os.path.join(out_dir, f"data_index_flat_{name}.json")
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        logger.info(f"âœ… å·²ä¿å­˜ {name} ç´¢å¼•: {save_path} ({sum(len(v) for v in data.values())} æ¡è®°å½•)")

    logger.info("ğŸ¯ æ•°æ®é›†æ‹†åˆ†å®Œæˆã€‚")
    return subsets

if __name__ == "__main__":
    with logging_redirect_tqdm():
        # json_index = build_flat_data_index(
        #     base_dir="/home/dataset-assist-1/SevereWeather_AI_2025",
        #     save_path="/home/dataset-assist-0/data/wind_radar_files.json"
        # )
        split_data_index(
            json_path="/home/dataset-assist-0/data/wind_radar_files.json",
            out_dir="/home/dataset-assist-0/data",
            train_ratio=0.8,
            eval_ratio=0.1,
            test_ratio=0.1
        )